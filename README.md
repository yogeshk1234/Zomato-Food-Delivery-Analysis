### Data Cleaning

After successfully scraping the data, a critical step was performed to enhance the quality and reliability of the dataset. This involved a thorough examination and cleaning process to address potential issues that could impact the accuracy of our analyses and insights.

**Key Data Cleaning Steps:**

1. **Handling Null Values:**
    - Identified and addressed missing values within the dataset, employing appropriate techniques for imputation based on statistical measures.
2. **Duplicate Values Removal:**
    - Detected and eliminated duplicate records to ensure the dataset was free from redundant information, preventing skewed analyses.

 3.   **Data Type Standardization:**

- Ensured appropriate data types for variables, such as converting numerical variables to the correct numeric data types and standardizing date formats.

# E.D.A. - Food Delivery Analysis

The following needs to be ensured while scraping:

- There have to be more than 500 restaurants.
- Once you have the database of tables created.
    - You need to generate aggregations and that will help you create a dashboard that should be able to help the end user with the following insights:
        - Area-wise distribution of restaurant
        - Which is the cheapest and most expensive restaurant for each type of cuisine.
        - Which location maximum number of restaurants where the `delivery_review_number` is greater than 1000?
        - Generate any one interesting insight from the data.
        - Which location maximum number of the less-rated restaurant?
        - Area wise cheap and expensive restaurant and their average price.
        - Number of restaurants for each type of cuisine.
    - You are hired by a consultancy firm, one of their clients wants to open a remote kitchen (Only delivery) in Banglore suggest to them which location will be suitable for their restaurant and what should be the price of different types of dishes in the early days.

